{
    "collab_server" : "",
    "contents" : "# if package kknn is not installed, run the following:\n#install.packages(\"kknn\")\n\n# dependencies\nlibrary(kknn)\n\n# load data\ndata = read.csv(\"spambase.csv\", header = TRUE, sep = \",\", quote = \"\\\"\",\n         dec = \",\", fill = TRUE, comment.char = \"\")\n\n# split data in half for train/test portions, \n# selecting documents randomly \nn = dim(data)[1]\nset.seed(12345)\nid = sample(1:n, floor(n*0.5))\ntrain = data[id,]\ntest = data[-id,]\n\nknearest=function(train_data, k, test_data) \n{\n  # get number of data points in train & test data\n  num_rows_train = dim(train_data)[1]\n  num_rows_test = dim(test_data)[1]\n  # get the classification column\n  spam_column = dim(train_data)[2]\n  # set up a vector for the classification probabilities\n  probabilities = numeric(num_rows_test)\n  # set up test and train matrices with the classification column removed\n  x_matrix = as.matrix(train_data[, -spam_column])\n  y_matrix = as.matrix(test_data[, -spam_column])\n\n  # X-hat and Y-hat\n  x_hat = x_matrix / matrix(sqrt(rowSums(x_matrix^2)), nrow=num_rows_train, ncol=spam_column-1)\n  y_hat = y_matrix / matrix(sqrt(rowSums(y_matrix^2)), nrow=num_rows_test, ncol=spam_column-1)\n  \n  # the cosine similarities of Yn with Xn\n  cosine_similarities = x_hat %*% t(y_hat)\n  \n  # the distances expressed as 1 - <the similarity>\n  distances = 1 - cosine_similarities\n\n  for (i in 1:num_rows_test) {\n    # sort the distances for every instance in the test data \n    # and select the row names of 5 documents that are closest to i\n    k_nearest_objects = names(sort(distances[, i])[1:k])\n    \n    # get the mean of spam classifications (values at 'spam_column') from the \n    # training data that corresponds to the row names in nearest_document\n    probabilities[i] = mean(train_data[c(k_nearest_objects), spam_column])\n  }\n  return (probabilities)\n}\n\nget_confusion_matrix=function(classification_probabilities, test_data) {\n  # round the classification probabilities to get predicted class\n  predicted_classifications = round(classification_probabilities)\n  # get the true classifications from the 'Spam' column of the test data \n  true_classifications = test_data$Spam\n  # create the confusion matrix for the predicted and true classifications\n  return (table(predicted_classifications, true_classifications))\n}\n\n# get the fraction of incorrect classifications (one minus sum of the diagonal over the total sum)\nmissclassification_rate=function(confusion_matrix) {\n  return (1 - (sum(diag(confusion_matrix)) / sum(confusion_matrix)))\n}\n\n# get probabilites and confusion matrix for our knearest classifier using k=5\nprobs_knearest5 = knearest(train, 5, test)\ncm_knearest5 = get_confusion_matrix(probs_knearest5, test)\nprint(\"CM for our knearest classifier using k=5:\")\nprint(cm_knearest5)\nprint(\"missclassification rate:\")\nprint(missclassification_rate(cm_knearest5))\n\n# repeat process for k=1\nprobs_knearest1 = knearest(train, 1, test)\ncm_knearest1 = get_confusion_matrix(probs_knearest1, test)\nprint(\"CM for our knearest classifier using k=1:\")\nprint(cm_knearest1)\nprint(\"missclassification rate:\")\nprint(missclassification_rate(cm_knearest1))\n\n# repeat again but using kknn classifier from the kknn package with k=5\nkknn5 = kknn(formula=Spam~., train=train, test=test, k=5)\nprobs_kknn5 = fitted.values(kknn5)\ncm_kknn5 = get_confusion_matrix(probs_kknn5, test)\nprint(\"CM for kknn classifier using k=5:\")\nprint(cm_kknn5)\nprint(\"missclassification rate:\")\nprint(missclassification_rate(cm_kknn5))\n\n# repeat with kknn using k=1\nkknn1 = kknn(formula=Spam~., train=train, test=test, k=1)\nprobs_kknn1 = fitted.values(kknn1)\ncm_kknn1 = get_confusion_matrix(probs_kknn1, test)\nprint(\"CM for kknn classifier using k=1:\")\nprint(cm_kknn1)\nprint(\"missclassification rate:\")\nprint(missclassification_rate(cm_kknn1))\n\n# classify_seq = seq(0.05, 0.95, by=0.05)\n# my_test = c(0.99, 0.94, 0.3, 0.2, 0.1)\n# my_out = sapply(my_test, function(x) as.numeric(x > classify_seq))\n# print(my_out)\n\n# with sequence 'classify_seq' to make spam classifications instead of using round()\n# each row in resulting matrix will correspond to classfications using a value from a sequence\nclassify_seq = seq(0.05, 0.95, by=0.05)\nclasses_by_seq_knearest5 = sapply(probs_knearest5, function(x) as.numeric(x > classify_seq))\nclasses_by_seq_kknn5 = sapply(probs_kknn5, function(x) as.numeric(x > classify_seq))\n\nprint(nrow(classes_by_seq_knearest5))\nprint(ncol(classes_by_seq_knearest5))\n\n# the fraction of true positives over (true positives + false positives) = specificity\nprecision=function(predicted_classifications, true_classifications) {\n  return (sum(predicted_classifications == 1 & true_classifications == 1) / \n            (sum(predicted_classifications == 1 & true_classifications == 1) +\n             sum(predicted_classifications == 1 & true_classifications == 0)))\n}\n\n# TPR the fraction of true positives over (true positives + false negatives) = sensitivity\nrecall=function(predicted_classifications, true_classifications) {\n  return (sum(predicted_classifications == 1 & true_classifications == 1) / \n            (sum(predicted_classifications == 1 & true_classifications == 1) +\n             sum(predicted_classifications == 0 & true_classifications == 1)))\n}\n\nFPR=function(predicted_classifications, true_classifications) {\n  return (sum(predicted_classifications == 1 & true_classifications == 0) / \n            (sum(predicted_classifications == 1 & true_classifications == 0) +\n               sum(predicted_classifications == 0 & true_classifications == 0)))\n}\n\n# apply precision and recall functions to each row in matrix generated by classes\n# using the different values from the sequence, using knearest model with k=5\nprecision_knearest5 = apply(classes_by_seq_knearest5, 1, precision, true_classifications=test$Spam)\nrecall_knearest5 = apply(classes_by_seq_knearest5, 1, recall, true_classifications=test$Spam)\n\n# the same using the kknn model with k=5\nprecision_kknn5 = apply(classes_by_seq_kknn5, 1, precision, true_classifications=test$Spam)\nrecall_kknn5 = apply(classes_by_seq_kknn5, 1, recall, true_classifications=test$Spam)\n\nFPR_knearest = apply(classes_by_seq_knearest5, 1, FPR, true_classifications=test$Spam)\n\nplot(classify_seq, classify_seq, \n     main=\"ROC-curves for knearest and kknn models\", \n     xlab=\"FPR or (1 - precision)\", ylab=\"TPR or recall\", \n     xlim=c(0.05, 0.95), ylim=c(0.05, 0.95))\nlines(FPR_knearest, recall_knearest5, col=\"Blue\")\n#lines(1 - precision_kknn5, recall_kknn5, col=\"Green\")\nabline(0, 1, col=\"Red\")",
    "created" : 1510306551119.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1036476170",
    "id" : "7EDF323",
    "lastKnownWriteTime" : 1510307911,
    "last_content_update" : 1510307911526,
    "path" : "~/TDDE01/lab1/lab1_assignment1/assignment1.R",
    "project_path" : "assignment1.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}