{
    "collab_server" : "",
    "contents" : "library(tree)\nlibrary(e1071)\n\ndata = read.csv(\"creditscoring.csv\", header = TRUE, \n                sep = \",\", quote = \"\\\"\", dec = \".\", \n                fill = TRUE, comment.char = \"\")\n\n# data split into training/validation/test as 50/25/25\n\n# use half data for training\nn = length(data[, 1])\nset.seed(12345)\nid = sample(1:n, floor(n * 0.5))\ntrain = data[id, ]\nremainder = data[-id, ]\n\n# split the remaining data into validation/test\nn = length(remainder[, 1])\nid = sample(1:n, floor(n * 0.5))\nvalidation = remainder[id, ]\ntest = remainder[-id, ]\n\n# fit one model using deviance (cross-entropy)\nmodel.deviance = tree(formula = good_bad ~ ., \n                      data = train,\n                      split = \"deviance\")\n\n# and another using gini-index\nmodel.gini = tree(formula = good_bad ~ ., \n                  data = train,\n                  split = \"gini\")\n\nget_misclass_rate=function(model, data)\n{\n  cm = get_confusion_matrix(model, data)\n  misclass_rate = (cm[1,2] + cm[2,1]) / sum(cm)\n  return (misclass_rate)\n}\n\nget_confusion_matrix=function(model, data)\n{\n  prediction = predict(model, \n                       newdata = data, \n                       type = \"class\")\n  cm = table(prediction, data$good_bad)\n  return (cm)\n}\n\ncat(\"\\nmisclass rate using 'deviance' for train data: \", \n    get_misclass_rate(model.deviance, train),\n    \"\\nmisclass rate using 'deviance' for test data: \",\n    get_misclass_rate(model.deviance, test),\n    \"\\nmisclass rate using 'gini' for train data: \", \n    get_misclass_rate(model.gini, train),\n    \"\\nmisclass rate using 'gini' for test data: \",\n    get_misclass_rate(model.gini, test))\n\n# deviance provides lower misclassification rate for both tests\n# chose model.deviance for pruning\n\ntrain_score = numeric(9)\nvalidation_score = numeric(9)\n\n# try number of terminal nodes in range 2-9 to find\n# optimal depth, i.e tree with lowest deviance\nfor (i in 2:9)\n{\n  pruned_tree = prune.tree(model.deviance, best = i)\n  prediction = predict(pruned_tree, \n                       newdata = validation, \n                       type = \"tree\")\n  train_score[i] = deviance(pruned_tree)\n  validation_score[i] = deviance(prediction)\n}\n\nplot(2:9, train_score[2:9], \n     type=\"b\", col=\"red\", ylim=c(250, 590),\n     xlab=\"Number of leaves\", ylab=\"Deviance\")\n\npoints(2:9, validation_score[2:9], \n       type=\"b\", col=\"blue\")\n\n# since i = 2..9, optimal i is equal to index + 1\noptimal.leaves = which.min(validation_score[2:9]) + 1\n# prune tree to optimal number of leaves\noptimal.tree = prune.tree(model.deviance, \n                          best = optimal_leaves)\n# get variables selected of optimal tree\nsummary(optimal.tree)\n# Variables actually used in tree construction:\n# \"savings\"  \"duration\" \"history\" \n\n# print the optimal tree\n# depth = 3 (if root depth = 0)\nplot(optimal.tree)\ntext(optimal.tree)\n\n# get misclassification rate for optimal tree on test data\noptimal.misclass = get_misclass_rate(optimal.tree, test)\ncat(\"\\nmisclass rate of optimal tree:\", optimal.misclass)\n\n# fit a naive bayes model to train data\nmodel.bayes = naiveBayes(formula = good_bad ~ ., \n                         data = train)\n\n# misclass-rate is higher for train than test..\ncat(\"\\nmisclass rate for naive bayes model on train data:\",\n    get_misclass_rate(model.bayes, train),\n    \"\\nmisclass rate for naive bayes model on test data:\",\n    get_misclass_rate(model.bayes, test))\n\ncat(\"\\n\\nCM for naiveBayes (train):\")\nprint(get_confusion_matrix(model.bayes, train))\ncat(\"\\nCM for naiveBayes (test):\")\nprint(get_confusion_matrix(model.bayes, test))\n\n# get raw probabilities for both classes from naiveBayes classifier\nraw.train = predict(model.bayes, newdata = train, type = \"raw\")\nraw.test = predict(model.bayes, newdata = test, type = \"raw\")\n\n# predicting 'good' must be 10x more probable than bad\n# to make the prediction 'good' with new loss-matrix \npreds.train = (raw.train[, 2] / raw.train[, 1]) > 10\npreds.test = (raw.test[, 2] / raw.test[, 1]) > 10\n\n# convert booleans to good/bad labels\npreds.train[which(preds.train == TRUE)] = \"good\"\npreds.train[which(preds.train == FALSE)] = \"bad\"\npreds.test[which(preds.test == TRUE)] = \"good\"\npreds.test[which(preds.test == FALSE)] = \"bad\"\n\n# CM for train and test\ncm.train = table(preds.train, train$good_bad)\ncm.test = table(preds.test, test$good_bad)\n\ncat(\"\\nCM for naiveBayes + new loss matrix (train):\")\nprint(cm.train)\ncat(\"\\nCM for naiveBayes + new loss matrix (test):\")\nprint(cm.test)\n\n# misclass-rate for train and test\nmisclass.train = (cm.train[1,2] + cm.train[2,1]) / sum(cm.train)\nmisclass.test = (cm.test[1,2] + cm.test[2,1]) / sum(cm.test)\n\ncat(\"\\nmisclass rate naiveBayes + new loss matrix (train data):\",\n    misclass.train,\n    \"\\nmisclass rate naiveBayes + new loss matrix (test data):\",\n    misclass.test)",
    "created" : 1510843489463.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1927218385",
    "id" : "290B50DF",
    "lastKnownWriteTime" : 1511182033,
    "last_content_update" : 1511182033,
    "path" : "~/TDDE01/lab2/assignment2/credit.R",
    "project_path" : "credit.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}