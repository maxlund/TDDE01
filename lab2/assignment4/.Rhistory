plot(W_prime[, 1], -W_prime[, 2])
plot(loads[, 2], type="b")
plot(W_prime[, 1], -W_prime[, 2])
plot(W_prime[, 1], W_prime[, 2])
plot(W_prime[, 2])
plot(loads[, 1], type="b")
plot(features, main="PCA of different spectras")
plot(res)
hist(res)
hist(as.numeric(res))
summary(features)
?pcr
library(fastICA)
library(pls)
set.seed(12345)
data = read.csv("NIRSpectra.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# ************************ TODO:
# Should we remove the 'Viscosity' column when doing PCA etc??
# ************************
features = princomp(data[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlab="PC1", ylab="PC2", xlim=x_lim, ylim=y_lim)
# for comparison, if we look at ex. PC1 vs PC5:
# plot(features$scores[ ,1], features$scores[ ,16], xlab="PC1", ylab="PC2", xlim=x_lim, ylim=y_lim)
# .. all the variance is explained by PC1
loads = loadings(features)
plot(loads[, 1], type="b")
plot(loads[, 2], type="b")
# ************************ TODO:
# Is there any principle component that is explained by mainly a few original features?
# ************************
res = fastICA(data[ ,-ncol(data)], 2, fun = "logcosh", alpha = 1.0,
row.norm = FALSE, maxit = 200, tol = 0.0001, verbose = TRUE)
# K = pre-whitening matrix that projects data onto the first n.comp principal components.
# W = estimated un-mixing matrix
# ************************ TODO:
# What is W_prime??
# ************************
W_prime = res$K %*% res$W
plot(W_prime[, 1])
plot(W_prime[, 2])
# ************************ TODO:
# Make a plot of the scores of the first two latent features and compare
# it with the score plot from step 1
# ***********************
pcr.fit = pcr(formula = Viscosity ~ .,
data = data,
validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
library(fastICA)
library(pls)
set.seed(12345)
data = read.csv("NIRSpectra.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# ************************ TODO:
# Should we remove the 'Viscosity' column when doing PCA etc??
# ************************
features = princomp(data[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlab="PC1", ylab="PC2", xlim=x_lim, ylim=y_lim)
# for comparison, if we look at ex. PC1 vs PC5:
# plot(features$scores[ ,1], features$scores[ ,16], xlab="PC1", ylab="PC2", xlim=x_lim, ylim=y_lim)
# .. all the variance is explained by PC1
loads = loadings(features)
plot(loads[, 1], type="b")
plot(loads[, 2], type="b")
# ************************ TODO:
# Is there any principle component that is explained by mainly a few original features?
# ************************
res = fastICA(data[ ,-ncol(data)], 2, fun = "logcosh", alpha = 1.0,
row.norm = FALSE, maxit = 200, tol = 0.0001, verbose = TRUE)
# K = pre-whitening matrix that projects data onto the first n.comp principal components.
# W = estimated un-mixing matrix
# ************************ TODO:
# What is W_prime??
# ************************
W_prime = res$K %*% res$W
plot(W_prime[, 1])
plot(W_prime[, 2])
# ************************ TODO:
# Make a plot of the scores of the first two latent features and compare
# it with the score plot from step 1
# ***********************
pcr.fit = pcr(formula = Viscosity ~ .,
data = data,
validation = "CV")
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,5))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,10))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,20))
library(fastICA)
library(pls)
set.seed(12345)
data = read.csv("NIRSpectra.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# ************************ TODO:
# Should we remove the 'Viscosity' column when doing PCA etc??
# ************************
features = princomp(data[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlab="PC1", ylab="PC2", xlim=x_lim, ylim=y_lim)
# for comparison, if we look at ex. PC1 vs PC5:
# plot(features$scores[ ,1], features$scores[ ,16], xlab="PC1", ylab="PC2", xlim=x_lim, ylim=y_lim)
# .. all the variance is explained by PC1
loads = loadings(features)
plot(loads[, 1], type="b")
plot(loads[, 2], type="b")
# ************************ TODO:
# Is there any principle component that is explained by mainly a few original features?
# ************************
res = fastICA(data[ ,-ncol(data)], 2, fun = "logcosh", alpha = 1.0,
row.norm = FALSE, maxit = 200, tol = 0.0001, verbose = TRUE)
# K = pre-whitening matrix that projects data onto the first n.comp principal components.
# W = estimated un-mixing matrix
# ************************ TODO:
# What is W_prime??
# ************************
W_prime = res$K %*% res$W
plot(W_prime[, 1])
plot(W_prime[, 2])
# ************************ TODO:
# Make a plot of the scores of the first two latent features and compare
# it with the score plot from step 1
# ***********************
pcr.fit = pcr(formula = Viscosity ~ .,
data = data,
validation = "CV")
validationplot(pcr.fit, val.type = "MSEP", xlim=c(10,30))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(1,30))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(5,10))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,10))
validationplot(pcr.fit, val.type = "MSEP")#, xlim=c(0,10))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,10))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,20))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,20))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,12))
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,10))
library(fastICA)
library(pls)
set.seed(12345)
data = read.csv("NIRSpectra.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# ************************ TODO:
# Should we remove the 'Viscosity' column when doing PCA etc??
# ************************
features = princomp(data[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlab="PC1", ylab="PC2", xlim=x_lim, ylim=y_lim)
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
plot(features$scores[ ,1], features$scores[ ,3], xlim=x_lim, ylim=y_lim)
plot(features$scores[ ,1], features$scores[ ,10], xlim=x_lim, ylim=y_lim)
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
plot(features$scores[ ,2], features$scores[ ,10], xlim=x_lim, ylim=y_lim)
library(fastICA)
library(pls)
set.seed(12345)
data = read.csv("NIRSpectra.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# ************************ TODO:
# Should we remove the 'Viscosity' column when doing PCA etc??
# ************************
features = princomp(data)#[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
data2=data
data2=data
data2$Viscosity = c()
features = princomp(data2)#[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
plot(features$scores[ ,1], features$scores[ ,3], xlim=x_lim, ylim=y_lim)
plot(features$scores[ ,2], features$scores[ ,3], xlim=x_lim, ylim=y_lim)
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
library(fastICA)
library(pls)
set.seed(12345)
data = read.csv("NIRSpectra.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# ************************ TODO:
# Should we remove the 'Viscosity' column when doing PCA etc??
# ************************
features = princomp(data)#[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
library(fastICA)
library(pls)
set.seed(12345)
data = read.csv("NIRSpectra.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# ************************ TODO:
# Should we remove the 'Viscosity' column when doing PCA etc??
# ************************
features = princomp(data[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
loads = loadings(features)
plot(loads[, 1], type="b")
plot(loads[, 2], type="b")
plot(loads[, 1], type="b")
plot(loads[, 2], type="b")
plot(loads[, 2], type="b")
plot(loads[, 2], type="b")
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
plot(W_prime[, 1])
# ************************
W_prime = res$K %*% res$W
plot(W_prime[, 1])
plot(W_prime[, 2])
library(fastICA)
library(pls)
set.seed(12345)
data = read.csv("NIRSpectra.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# ************************ TODO:
# Should we remove the 'Viscosity' column when doing PCA etc??
# ************************
features = princomp(data[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
# for comparison, if we look at ex. PC1 vs PC5:
# plot(features$scores[ ,1], features$scores[ ,16], xlab="PC1", ylab="PC2", xlim=x_lim, ylim=y_lim)
# .. all the variance is explained by PC1
loads = loadings(features)
plot(loads[, 1], type="b")
plot(loads[, 2], type="b")
# which has 0 load? those contribute nothing to the linear transformation,
# LOAD = how much a feature contribute to the variance within a principal component
# i.e. how much does one dimension contribute to the variance along the dimension of the PC.
# ************************ TODO:
# Is there any principle component that is explained by mainly a few original features?
# YES PC2, there are a lot of features that are around 0
# ************************
res = fastICA(data[ ,-ncol(data)], 2, fun = "logcosh", alpha = 1.0,
row.norm = FALSE, maxit = 200, tol = 0.0001, verbose = TRUE)
# K = pre-whitening matrix that projects data onto the first n.comp principal components.
# W = estimated un-mixing matrix
# ************************ TODO:
# What is W_prime??
# ************************
W_prime = res$K %*% res$W
plot(W_prime[, 1])
plot(W_prime[, 2])
plot(W_prime[, 1])
plot(loads[, 1], type="b")
par(mfrow =c(1,2))
plot(loads[, 1], type="b")
plot(W_prime[, 1])
par(mfrow =c(1,2))
plot(loads[, 2], type="b")
plot(W_prime[, 2])
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
# Should we remove the 'Viscosity' column when doing PCA etc??
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
str(res)
validationplot(pcr.fit, val.type = "MSEP")
pcr.fit = pcr(formula = Viscosity ~ .,
data = data,
validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
# it seems after choosing more than 6 components, the MSEP doesn't go down much
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,10))
# TODO: Correct to say # components to select = 6??
validationplot(pcr.fit, val.type = "MSEP")
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,10))
par(mfrow=c(1,2))
validationplot(pcr.fit, val.type = "MSEP")
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,10))
library(tree)
library(boot)
set.seed(12345)
data = read.csv("State.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# sort data by variable MET (desc)
data.ordered = data[order(data$MET),]
# plot EX vs MET
plot(data.ordered$MET, data.ordered$EX)
# fit a tree model, #observations in leaf >= 8
model = tree(formula = EX ~ MET,
data = data.ordered,
control = tree.control(nrow(data.ordered), minsize = 8))
# perform cross-validation on model
model.cv = cv.tree(model)
plot(model.cv, type="p")
# select optimal number of leaves
best.size = model.cv$size[which(model.cv$dev==min(model.cv$dev))]
# prune tree using selected num of leaves from CV
model.optimal = prune.tree(model, best = best.size)
# report the selected tree
summary(model.optimal)
#*****
# TODO: plot original and fitted data..
#*****
# like this?
fitted_data = predict(model.optimal, newdata = data.ordered)
plot(data.ordered$MET, data.ordered$EX, col = "green")
points(data.ordered$MET, fitted_data, col = "red")
# histogram of residuals
hist(resid(model.optimal))
# function that produces the statistics for the nonparametric bootstrap function boot()
nonparametric=function(data, index)
{
sample = data[index, ]
model = tree(formula = EX ~ MET,
data = sample,
control = tree.control(nrow(sample), minsize = 8))
model.pruned = prune.tree(model, best = best.size)
prediction = predict(model.pruned, newdata = data.ordered)
return (prediction)
}
# same for parametric boostrapping
parametric=function(data)
{
model = tree(formula = EX ~ MET,
data = data,
control = tree.control(nrow(data), minsize = 8))
model.pruned = prune.tree(model, best = best.size)
prediction = predict(model.pruned, newdata = data.ordered)
return (prediction)
}
# generate some new data for EX
rng=function(data, mle)
{
new_data = data.frame(EX = data$EX, MET = data$MET)
n = length(data$EX)
new_data$EX = rnorm(n, predict(mle, newdata = data), sd(resid(mle)))
return(new_data)
}
prediction=function(data)
{
model = tree(formula = EX ~ MET,
data = data,
control = tree.control(nrow(data), minsize = 8))
model.pruned = prune.tree(model, best = best.size)
preds = predict(model.pruned, newdata = data.ordered)
n = length(data.ordered$EX)
preds_ = rnorm(n, preds, sd(resid(model.optimal)))
return (preds_)
}
boot.nonparam = boot(data = data.ordered,
statistic = nonparametric,
R = 1000)
boot.nonparam.cb = envelope(boot.nonparam, level = 0.95)
#plot(boot.nonparam)
# plot MET vs EX, predictions and
# confidence bands for model's predictions
plot(data.ordered$MET, data.ordered$EX, col = "black", main = "Confidence bands (non-parametric)")
points(data.ordered$MET, fitted_data, col = "red")
lines(data.ordered$MET, boot.nonparam.cb$point[1, ], col="blue")
lines(data.ordered$MET, boot.nonparam.cb$point[2, ], col="blue")
legend("topright", legend=c("Confidence bands"),
col=c("blue"), lty=1, cex=0.8)
boot.param = boot(data = data.ordered,
statistic = parametric,
R = 1000,
mle = model.optimal,
ran.gen = rng,
sim = "parametric")
boot.param.preds = boot(data = data.ordered,
statistic = prediction,
R = 1000,
mle = model.optimal,
ran.gen = rng,
sim = "parametric")
boot.param.cb = envelope(boot.param, level = 0.95)
boot.param.pb = envelope(boot.param.preds, level = 0.95)
# same for parametric bootstrapping
plot(boot.param)
plot(data.ordered$MET, data.ordered$EX, col="black",
main="Confidence and prediction bands (parametric)", ylim=c(100, 500))
points(data.ordered$MET, fitted_data, col = "red")
lines(data.ordered$MET, boot.param.cb$point[1, ], col="blue")
lines(data.ordered$MET, boot.param.cb$point[2, ], col="blue")
lines(data.ordered$MET, boot.param.pb$point[1, ], col="orange")
lines(data.ordered$MET, boot.param.pb$point[2, ], col="orange")
legend("topright", legend=c("Confidence bands", "Prediction bands"),
col=c("blue", "orange"), lty=1, cex=0.8)
plot(res$S[, 1], res$S[, 2], main = "Scores of first two latent features in fastICA")
library(fastICA)
library(pls)
set.seed(12345)
data = read.csv("NIRSpectra.csv", header = TRUE,
sep = ";", dec = ",", fill = TRUE)
# ************************ TODO:
# Should we remove the 'Viscosity' column when doing PCA etc??
# ************************
features = princomp(data[, -ncol(data)])
summary(features)
# First 3 components:
# Proportion of Variance: 0.9463514 0.05008087 0.003372371
# Proportion of variance in PC1 + PC2 = 0.9333233 + 0.06263367 = 0.9959569699999999 > 0.99
# -- we choose PC1 and PC2.
plot(features, main="PCA of different spectras")
# plot of PC1 vs PC2
x_lim = c(min(features$scores[ ,1]), max(features$scores[ ,1]))
y_lim = c(min(features$scores[ ,2]), max(features$scores[ ,2]))
plot(features$scores[ ,1], features$scores[ ,2], xlim=x_lim, ylim=y_lim)
# for comparison, if we look at ex. PC1 vs PC5:
# plot(features$scores[ ,1], features$scores[ ,16], xlab="PC1", ylab="PC2", xlim=x_lim, ylim=y_lim)
# .. all the variance is explained by PC1
loads = loadings(features)
par(mfrow=c(1,2))
plot(loads[, 1], type="b")
plot(loads[, 2], type="b")
# which has 0 load? those contribute nothing to the linear transformation,
# LOAD = how much a feature contribute to the variance within a principal component
# i.e. how much does one dimension contribute to the variance along the dimension of the PC.
# ************************ TODO:
# Is there any principle component that is explained by mainly a few original features?
# YES PC2, there are a lot of features that are around 0
# ************************
res = fastICA(data[ ,-ncol(data)], 2, fun = "logcosh", alpha = 1.0,
row.norm = FALSE, maxit = 200, tol = 0.0001, verbose = TRUE)
str(res)
# K = pre-whitening matrix that projects data onto the first n.comp principal components.
# W = estimated un-mixing matrix
# ************************ TODO:
# What is W_prime??
# ************************
W_prime = res$K %*% res$W
plot(W_prime[, 1])
plot(W_prime[, 2])
# ************************ TODO:
# Make a plot of the scores of the first two latent features and compare
# it with the score plot from step 1
# lookup str(res) -- S ?
# ***********************
plot(res$S[, 1], res$S[, 2], main = "Scores of first two latent features in fastICA")
pcr.fit = pcr(formula = Viscosity ~ .,
data = data,
validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
# it seems after choosing more than 6 components, the MSEP doesn't go down much
validationplot(pcr.fit, val.type = "MSEP", xlim=c(0,10))
# TODO: Correct to say # components to select = 6??
par(mfrow=c(1,1))
plot(res$S[, 1], res$S[, 2], main = "Scores of first two latent features in fastICA")
